{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplement A_Guide_to_Running_Tensorflow_Models_on_Android/Instructions.ipynb with more details    \n",
    "Add comments on code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "There is another example:    \n",
    "https://github.com/guihongwan/PlaygroundOfTensorFlow/#Tutorials#Building a Convolutional Neural Network for MNIST.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.6.0\n",
    "# tensorflow 1.1.0\n",
    "# Keras 2.0.4\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "MODEL_NAME = 'mnist_convnet'\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    #print(x_train.shape)#(60000, 28, 28)\n",
    "    #print(x_test.shape)#(10000, 28, 28)\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) # 784\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255 #the minumum value of color is 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    #print(y_test) #[7 2 1 ... 4 5 6]\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    #print(y_test)\n",
    "    #[[0. 0. 0. ... 1. 0. 0.]\n",
    "    #[0. 0. 1. ... 0. 0. 0.]\n",
    "    #[0. 1. 0. ... 0. 0. 0.]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential() #a linear stack of layers https://keras.io\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 64] \n",
    "    model.add(Conv2D(filters=64, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu', \\\n",
    "            input_shape=[28, 28, 1]))\n",
    "    # 28*28*64\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    # 14*14*64\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu'))\n",
    "    # 14*14*128\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    # 7*7*128\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu'))\n",
    "    # 7*7*256\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    # 4*4*256, because padding='same'\n",
    "\n",
    "    model.add(Flatten()) #[bathsize,4*4*256]\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \\\n",
    "                  optimizer=keras.optimizers.Adadelta(), \\\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, \\\n",
    "              batch_size=BATCH_SIZE, \\\n",
    "              epochs=EPOCHS, \\\n",
    "              verbose=1, \\\n",
    "              validation_data=(x_test, y_test))\n",
    "    \n",
    "# export model for andorid\n",
    "def export_model(saver, model, input_node_names, output_node_name):\n",
    "    tf.train.write_graph(K.get_session().graph_def, 'out', \\\n",
    "        MODEL_NAME + '_graph.pbtxt') #writes a graph proto to a file\n",
    "\n",
    "    saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')\n",
    "    \n",
    "    freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \\\n",
    "        False, 'out/' + MODEL_NAME + '.chkp', output_node_name, \\\n",
    "        \"save/restore_all\", \"save/Const:0\", \\\n",
    "        'out/frozen_' + MODEL_NAME + '.pb', True, \"\")\n",
    "    \n",
    "    #Optimize for inference\n",
    "    input_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\n",
    "        input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "            input_graph_def, input_node_names, [output_node_name],\n",
    "            tf.float32.as_datatype_enum)\n",
    "\n",
    "    with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    print(\"graph saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not path.exists('out'):\n",
    "        os.mkdir('out')\n",
    "\n",
    "    x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    train(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "    export_model(tf.train.Saver(), model, [\"conv2d_1_input\"], \"dense_2/Softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 531s 9ms/step - loss: 0.5903 - acc: 0.8165 - val_loss: 0.1883 - val_acc: 0.9372\n",
      "INFO:tensorflow:Restoring parameters from out/mnist_convnet.chkp\n",
      "INFO:tensorflow:Froze 10 variables.\n",
      "Converted 10 variables to const ops.\n",
      "graph saved!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# App Architecture\n",
    "\n",
    "List<Classifier> mClassifiers:    \n",
    "loadModel(): mClassifiers.add(TensorFlowClassifier.create())   \n",
    "    \n",
    "final Classification res = classifier.recognize(pixels);    \n",
    "\n",
    "res is the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "public interface <span class=\"mark\">Classifier</span> {    \n",
    "    String name();    \n",
    "    Classification recognize(final float[] pixels);    \n",
    "}    \n",
    "public class <span class=\"mark\">TensorFlowClassifier</span> implements Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlowClassifier\n",
    "\n",
    "<span class=\"mark\">TensorFlowInferenceInterface</span>:used as the window between android and tensorflow native C++    \n",
    "\n",
    "create():    \n",
    "c.tfHelper = new TensorFlowInferenceInterface(assetManager, <span class=\"mark\">modelPath</span>);    \n",
    "\n",
    "recognize(final float[] pixels):    \n",
    "tfHelper.<span class=\"mark\">feed</span>(inputName, pixels, 1, inputSize, inputSize, 1);      \n",
    "tfHelper.<span class=\"mark\">run</span>(outputNames);    \n",
    "tfHelper.<span class=\"mark\">fetch</span>(outputName, output);   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code of TensorFlowInferenceInterface\n",
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
